{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d127f4e",
   "metadata": {},
   "source": [
    "# ðŸ§ª Hands-On Lab for Section 2: Foundations of RAG Architecture\n",
    "\n",
    "**Lab Title:**\n",
    "Implementing the Retrieval and Generation Pipeline with FAISS and OpenAI LLM\n",
    "\n",
    "## Objective:\n",
    "By the end of this lab, learners will:\n",
    "- Build a retrieval subsystem that finds relevant text from a vector database.\n",
    "- Build a generation subsystem that uses LLMs to create context-aware answers.\n",
    "- Combine both to form a working RAG mini-architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6337e1",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2c1abeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (2.12.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (1.13.1)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (0.12.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (2.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from openai) (2.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\program files\\python311\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\program files\\python311\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai faiss-cpu tiktoken pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7b7ec",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6eca0fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenRouter client initialized\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variable\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if not OPENROUTER_API_KEY:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY not found! Please set it in your .env file\")\n",
    "\n",
    "# Initialize OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY\n",
    ")\n",
    "\n",
    "print(\"âœ… OpenRouter client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea16b2",
   "metadata": {},
   "source": [
    "## ðŸ§© Part 1 â€“ The Retrieval Process\n",
    "\n",
    "**Goal:** Understand how embeddings are created, stored, and searched using semantic similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d225c3",
   "metadata": {},
   "source": [
    "### Create a mini-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c300c27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base created with 5 documents\n"
     ]
    }
   ],
   "source": [
    "knowledge_base = [\n",
    "    \"RAG stands for Retrieval-Augmented Generation.\",\n",
    "    \"In RAG, relevant context is fetched before generating answers.\",\n",
    "    \"Vector databases such as FAISS store embeddings for fast search.\",\n",
    "    \"Embeddings represent text meaning as numerical vectors.\",\n",
    "    \"Combining retrieval and generation improves accuracy and factuality.\"\n",
    "]\n",
    "\n",
    "print(\"Knowledge base created with\", len(knowledge_base), \"documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd660c",
   "metadata": {},
   "source": [
    "### Generate embeddings and store in FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd89ac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (5.2.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\program files\\python311\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.12.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\program files\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\techp\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Generating embeddings...\n",
      "âœ… FAISS index created with 5 vectors of dimension 384\n"
     ]
    }
   ],
   "source": [
    "# Install sentence-transformers for local embeddings\n",
    "%pip install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize a local embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate embeddings using a local sentence transformer model\"\"\"\n",
    "    return embedding_model.encode(text).tolist()\n",
    "\n",
    "# Generate embeddings for all documents in knowledge base\n",
    "print(\"Generating embeddings...\")\n",
    "vectors = [get_embedding(text) for text in knowledge_base]\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = len(vectors[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(vectors).astype(\"float32\"))\n",
    "\n",
    "print(f\"âœ… FAISS index created with {index.ntotal} vectors of dimension {dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4ecd1",
   "metadata": {},
   "source": [
    "### Test retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25000cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches:\n",
      "\n",
      "1. RAG stands for Retrieval-Augmented Generation.\n",
      "2. In RAG, relevant context is fetched before generating answers.\n"
     ]
    }
   ],
   "source": [
    "query = \"How does RAG improve AI accuracy?\"\n",
    "\n",
    "# Get embedding for the query\n",
    "query_vector = get_embedding(query)\n",
    "\n",
    "# Search for top 2 most similar documents\n",
    "D, I = index.search(np.array([query_vector]).astype(\"float32\"), k=2)\n",
    "\n",
    "# Retrieve the matching documents\n",
    "retrieved_docs = [knowledge_base[i] for i in I[0]]\n",
    "\n",
    "print(\"Top matches:\\n\")\n",
    "for idx, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"{idx}. {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68490b2e",
   "metadata": {},
   "source": [
    "## ðŸ§  Part 2 â€“ The Generation Process\n",
    "\n",
    "**Goal:** Use an LLM to generate context-aware answers based on retrieved data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e6dd2",
   "metadata": {},
   "source": [
    "### Combine retrieved context and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f8bcf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt sent to LLM:\n",
      "------------------------------------------------------------\n",
      "Use the context below to answer precisely.\n",
      "\n",
      "Context:\n",
      "RAG stands for Retrieval-Augmented Generation. In RAG, relevant context is fetched before generating answers.\n",
      "\n",
      "Question: How does RAG improve AI accuracy?\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "context = \" \".join(retrieved_docs)\n",
    "prompt = f\"Use the context below to answer precisely.\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\"\n",
    "\n",
    "print(\"Prompt sent to LLM:\")\n",
    "print(\"-\" * 60)\n",
    "print(prompt)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50d4cf",
   "metadata": {},
   "source": [
    "### Generate the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c461f6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error: Error code: 404 - {'error': {'message': 'No endpoints found for qwen/qwen-2-7b-instruct:free.', 'code': 404}, 'user_id': 'user_2wfJyNuF5yzdHhNuld6ltJBaBZP'}\n",
      "\n",
      "Please verify:\n",
      "1. Your OPENROUTER_API_KEY in the .env file\n",
      "2. Get a fresh key from https://openrouter.ai/keys\n",
      "3. Restart the kernel and re-run from the beginning\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen/qwen-2-7b-instruct:free\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    print(\"Generated Answer:\\n\")\n",
    "    print(response.choices[0].message.content)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(\"\\nPlease verify:\")\n",
    "    print(\"1. Your OPENROUTER_API_KEY in the .env file\")\n",
    "    print(\"2. Get a fresh key from https://openrouter.ai/keys\")\n",
    "    print(\"3. Restart the kernel and re-run from the beginning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f169b6",
   "metadata": {},
   "source": [
    "## âš™ï¸ Part 3 â€“ Putting It Together\n",
    "\n",
    "**Goal:** Build a complete RAG function that takes a user question and returns a contextual answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f31ff2",
   "metadata": {},
   "source": [
    "### Define a complete RAG pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce12433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG pipeline function ready!\n"
     ]
    }
   ],
   "source": [
    "def rag_pipeline(question, k=2):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Retrieval + Generation\n",
    "    \n",
    "    Args:\n",
    "        question: User's question\n",
    "        k: Number of top documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Generated answer based on retrieved context\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant documents\n",
    "    q_vec = get_embedding(question)\n",
    "    D, I = index.search(np.array([q_vec]).astype(\"float32\"), k=k)\n",
    "    retrieved_docs = [knowledge_base[i] for i in I[0]]\n",
    "    context = \" \".join(retrieved_docs)\n",
    "    \n",
    "    print(f\"ðŸ“š Retrieved {k} relevant documents:\")\n",
    "    for idx, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"  {idx}. {doc}\")\n",
    "    print()\n",
    "    \n",
    "    # Step 2: Create prompt with context\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
    "    \n",
    "    # Step 3: Generate answer using OpenRouter\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen/qwen-2-7b-instruct:free\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"âœ… RAG pipeline function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b437465",
   "metadata": {},
   "source": [
    "### Ask your AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9958191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What are vector databases used for?\n",
      "------------------------------------------------------------\n",
      "ðŸ“š Retrieved 2 relevant documents:\n",
      "  1. Vector databases such as FAISS store embeddings for fast search.\n",
      "  2. Embeddings represent text meaning as numerical vectors.\n",
      "\n",
      "Vector databases, such as FAISS (Facebook AI Similarity Search), are used for efficient similarity search and retrieval of dense vector embeddings. These embeddings represent text, images, or other high-dimensional data as numerical vectors, allowing for fast and accurate querying of similar data points.\n",
      "\n",
      "Some common use cases for vector databases include:\n",
      "\n",
      "1. **Text Search and Recommendation**: Vector databases are used in search engines, recommender systems, and content recommendation platforms to find similar documents, articles, or products based on their vector embeddings.\n",
      "2. **Image Retrieval**: Vector databases are used in image retrieval applications, such as object detection, image classification, and facial recognition, to quickly identify similar images or objects.\n",
      "3. **Information Retrieval**: Vector databases are used in information retrieval systems, such as search engines and databases, to efficiently search and retrieve documents or data based on their vector embeddings.\n",
      "4. **Clustering and Grouping**: Vector databases can be used for clustering and grouping similar data points, allowing for the identification of patterns and relationships in large datasets.\n",
      "5. **Natural Language Processing (NLP)**: Vector databases are used in NLP applications, such as language modeling, sentiment analysis, and text classification, to represent text meaning as numerical vectors.\n",
      "6. **Facial Recognition and Biometrics**: Vector databases are used in facial recognition and biometric applications to represent face embeddings and identify individuals.\n",
      "7. **Content-Based Recommendation**: Vector databases are used in content-based recommendation systems to recommend products or content based on their vector embeddings.\n",
      "8. **Anomaly Detection**: Vector databases can be used for anomaly detection in large datasets, by identifying data points that are farthest from the mean vector.\n",
      "\n",
      "Overall, vector databases provide a powerful tool for efficiently searching, retrieving, and analyzing large amounts of high-dimensional data.\n",
      "\n",
      "============================================================\n",
      "\n",
      "Question 2: Explain the main advantage of RAG.\n",
      "------------------------------------------------------------\n",
      "ðŸ“š Retrieved 2 relevant documents:\n",
      "  1. RAG stands for Retrieval-Augmented Generation.\n",
      "  2. In RAG, relevant context is fetched before generating answers.\n",
      "\n",
      "The main advantage of Retrieval-Augmented Generation (RAG) is that it leverages the strengths of both information retrieval and generation techniques to produce high-quality answers.\n",
      "\n",
      "In traditional Generation models, the generator is responsible for producing an answer from scratch, without any additional information or context. However, this approach can lead to a lack of depth, accuracy, and relevance in the generated answer.\n",
      "\n",
      "RAG, on the other hand, first retrieves relevant context from a large dataset or knowledge base using a Retrieval component. This context is then used as input to a Generator component, which produces a more informed, accurate, and relevant answer.\n",
      "\n",
      "The main advantage of RAG is that it effectively combines the strengths of both retrieval and generation techniques. By first retrieving relevant context, RAG can:\n",
      "\n",
      "1. **Improve accuracy**: By leveraging pre-existing knowledge and context, RAG can generate answers that are more accurate and reliable.\n",
      "2. **Increase relevance**: RAG can tailor the answer to the specific question or prompt, making the generated answer more relevant and useful to the user.\n",
      "3. **Enhance depth**: By providing a foundation of context, RAG can generate answers that are more comprehensive and in-depth, covering a wider range of topics and subtopics.\n",
      "\n",
      "Overall, the main advantage of RAG is its ability to strike a balance between accuracy, relevance, and depth, producing high-quality answers that are more informative and useful to users.\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 1: What are vector databases used for?\")\n",
    "print(\"-\" * 60)\n",
    "# First, let's update the rag_pipeline function to use a working model\n",
    "def rag_pipeline_fixed(question, k=2):\n",
    "\t\"\"\"\n",
    "\tComplete RAG pipeline: Retrieval + Generation (with working model)\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tquestion: User's question\n",
    "\t\tk: Number of top documents to retrieve\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tGenerated answer based on retrieved context\n",
    "\t\"\"\"\n",
    "\t# Step 1: Retrieve relevant documents\n",
    "\tq_vec = get_embedding(question)\n",
    "\tD, I = index.search(np.array([q_vec]).astype(\"float32\"), k=k)\n",
    "\tretrieved_docs = [knowledge_base[i] for i in I[0]]\n",
    "\tcontext = \" \".join(retrieved_docs)\n",
    "\t\n",
    "\tprint(f\"ðŸ“š Retrieved {k} relevant documents:\")\n",
    "\tfor idx, doc in enumerate(retrieved_docs, 1):\n",
    "\t\tprint(f\"  {idx}. {doc}\")\n",
    "\tprint()\n",
    "\t\n",
    "\t# Step 2: Create prompt with context\n",
    "\tprompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
    "\t\n",
    "\t# Step 3: Generate answer using a working model\n",
    "\ttry:\n",
    "\t\tresponse = client.chat.completions.create(\n",
    "\t\t\tmodel=\"meta-llama/llama-3.2-3b-instruct:free\",  # Using a different free model\n",
    "\t\t\tmessages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "\t\t)\n",
    "\t\treturn response.choices[0].message.content\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error with meta-llama model: {e}\")\n",
    "\t\ttry:\n",
    "\t\t\t# Fallback to another model\n",
    "\t\t\tresponse = client.chat.completions.create(\n",
    "\t\t\t\tmodel=\"microsoft/phi-3-mini-128k-instruct:free\",\n",
    "\t\t\t\tmessages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "\t\t\t)\n",
    "\t\t\treturn response.choices[0].message.content\n",
    "\t\texcept Exception as e2:\n",
    "\t\t\treturn f\"Error generating response: {e2}\"\n",
    "\n",
    "answer1 = rag_pipeline_fixed(\"What are vector databases used for?\")\n",
    "print(answer1)\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(\"Question 2: Explain the main advantage of RAG.\")\n",
    "print(\"-\" * 60)\n",
    "answer2 = rag_pipeline_fixed(\"Explain the main advantage of RAG.\")\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab1bc32",
   "metadata": {},
   "source": [
    "## ðŸ§­ Bonus Challenge\n",
    "\n",
    "Try these experiments:\n",
    "\n",
    "1. **Replace the toy dataset** with your own text (PDF excerpts, company docs, or Wikipedia articles).\n",
    "2. **Experiment with different k values** (top-k retrieval) to see how it affects the quality of answers.\n",
    "3. **Compare responses with and without retrieval** to see the impact on factual accuracy.\n",
    "\n",
    "### Example: Compare with and without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3b056fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT RAG (No Context):\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'No endpoints found for qwen/qwen-2-7b-instruct:free.', 'code': 404}, 'user_id': 'user_2wfJyNuF5yzdHhNuld6ltJBaBZP'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWITHOUT RAG (No Context):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response_no_rag = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqwen/qwen-2-7b-instruct:free\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_question\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(response_no_rag.choices[\u001b[32m0\u001b[39m].message.content)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'No endpoints found for qwen/qwen-2-7b-instruct:free.', 'code': 404}, 'user_id': 'user_2wfJyNuF5yzdHhNuld6ltJBaBZP'}"
     ]
    }
   ],
   "source": [
    "test_question = \"What does RAG stand for?\"\n",
    "\n",
    "# Without RAG (direct query)\n",
    "print(\"WITHOUT RAG (No Context):\")\n",
    "print(\"-\" * 60)\n",
    "response_no_rag = client.chat.completions.create(\n",
    "    model=\"qwen/qwen-2-7b-instruct:free\",\n",
    "    messages=[{\"role\": \"user\", \"content\": test_question}]\n",
    ")\n",
    "print(response_no_rag.choices[0].message.content)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "# With RAG (context-aware)\n",
    "print(\"WITH RAG (Context-Aware):\")\n",
    "print(\"-\" * 60)\n",
    "response_with_rag = rag_pipeline(test_question)\n",
    "print(f\"\\nðŸŽ¯ Answer: {response_with_rag}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nâœ… Notice how RAG provides more specific, context-grounded answers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae3165",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Summary\n",
    "\n",
    "You've successfully built a complete RAG system! Here's what you accomplished:\n",
    "\n",
    "1. âœ… **Retrieval**: Created embeddings and stored them in FAISS for semantic search\n",
    "2. âœ… **Generation**: Used an LLM to generate context-aware answers\n",
    "3. âœ… **Integration**: Combined both into a single `rag_pipeline()` function\n",
    "4. âœ… **Comparison**: Saw the difference between RAG and non-RAG responses\n",
    "\n",
    "This is your first fully functional RAG mini-system!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
